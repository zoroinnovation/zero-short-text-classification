{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459f7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "d:\\Zoro_project2\\zero-short-text-classification\\py_3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jyoti\\.cache\\huggingface\\hub\\models--google--flan-t5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load FLAN-T5 model and tokenizer\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(\" Model loaded on\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97c1042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it 's a charming and often affecting journey .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>it s a charming and often affecting journey</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting , costumes , music , cinematography...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>the acting costumes music cinematography and s...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it 's slow -- very , very slow .</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>it s slow very very slow</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label  idx  \\\n",
       "0    it 's a charming and often affecting journey .       1    0   \n",
       "1                 unflinchingly bleak and desperate       0    1   \n",
       "2  allows us to hope that nolan is poised to emba...      1    2   \n",
       "3  the acting , costumes , music , cinematography...      1    3   \n",
       "4                  it 's slow -- very , very slow .       0    4   \n",
       "\n",
       "                                                text true_label  \n",
       "0        it s a charming and often affecting journey   Positive  \n",
       "1                  unflinchingly bleak and desperate   Negative  \n",
       "2  allows us to hope that nolan is poised to emba...   Positive  \n",
       "3  the acting costumes music cinematography and s...   Positive  \n",
       "4                           it s slow very very slow   Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\Zoro_project2\\zero-short-text-classification\\data_csv\\sst2_val.csv\").dropna(subset=[\"text\"])\n",
    "df[\"true_label\"] = df[\"label\"].map({1: \"Positive\", 0: \"Negative\"})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8167e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_prompt_template(path, template_number=1):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Match \"Template {number}: ...\" and capture until the next \"Template\" or EOF\n",
    "    pattern = rf\"Template {template_number}:(.*?)(?:Template \\d+:|$)\"\n",
    "    match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    if not match:\n",
    "        raise ValueError(f\"‚ùå Template {template_number} not found\")\n",
    "\n",
    "    raw_prompt = match.group(1).strip()\n",
    "\n",
    "    # Remove leading/trailing ======= and comments\n",
    "    cleaned_lines = [\n",
    "        line for line in raw_prompt.splitlines()\n",
    "        if line.strip() and not line.strip().startswith(\"#\") and not line.strip().startswith(\"=\")\n",
    "    ]\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines).strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e53b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracted Prompt Template:\n",
      " Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"{sentence}\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt_template = load_prompt_template(r\"D:\\Zoro_project2\\zero-short-text-classification\\prompts\\sst2_prompt_templates.txt\", template_number=1)\n",
    "print(\" Extracted Prompt Template:\\n\", prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f145f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(sentence):\n",
    "    return prompt_template.replace(\"{sentence}\", sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e65f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flan_predict(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=5)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e571055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñå         | 1/20 [00:20<06:36, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"it s a charming and often affecting journey\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 2/20 [00:41<06:09, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"unflinchingly bleak and desperate\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 3/20 [00:57<05:12, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 4/20 [01:11<04:27, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"the acting costumes music cinematography and sound are all astounding given the production s austere locales\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 5/20 [01:29<04:18, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"it s slow very very slow\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 6/20 [01:48<04:09, 17.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"although laced with humor and a few fanciful touches the film is a refreshingly serious look at young women\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [01:59<03:24, 15.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"a sometimes tedious film\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [02:07<02:40, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"or doing last year s taxes with your exwife\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9/20 [02:11<01:51, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"you do nt have to know about music to appreciate the film s easygoing blend of comedy and romance\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10/20 [02:14<01:21,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"in exactly 89 minutes most of which passed as slowly as if i d been sitting naked on an igloo formula 51 sank from quirky to jerky to utter turkey\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [02:17<00:59,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"the mesmerizing performances of the leads keep the film grounded and keep the audience riveted\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12/20 [02:21<00:45,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"it takes a strange kind of laziness to waste the talents of robert forster anne meara eugene levy and reginald veljohnson all in the same movie\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 13/20 [02:24<00:35,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"the film suffers from a lack of humor something needed to balance out the violence\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [02:36<00:42,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"we root for clara and paul even like them though perhaps it s an emotion closer to pity\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [02:46<00:39,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"even horror fans will most likely not find what they re seeking with trouble every day the movie lacks both thrills and humor\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16/20 [02:54<00:31,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"a gorgeous highspirited musical from india that exquisitely blends music dance song and high drama\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [03:02<00:23,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"the emotions are raw and will strike a nerve with anyone who s ever had family trauma\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18/20 [03:06<00:13,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"audrey tatou has a knack for picking roles that magnify her outrageous charm and in this literate french comedy she s as morningglory exuberant as she was in amlie\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Positive\n",
      "‚úÖ Cleaned Prediction: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [03:09<00:05,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"the movie is just a plain old monster\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [03:11<00:00,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Prompt: Direct Classification Style \n",
      "Classify the sentiment of the following sentence strictly as either Positive or Negative.\n",
      "Sentence: \"in its best moments resembles a bad high school production of grease without benefit of song\"\n",
      "Respond with exactly one word: Positive or Negative.\n",
      "Answer:\n",
      "üß† Raw Response: Negative\n",
      "‚úÖ Cleaned Prediction: Negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for _, row in tqdm(df.head(20).iterrows(), total=20):\n",
    "    prompt = generate_prompt(row[\"text\"])\n",
    "    output = flan_predict(prompt)  #  FLAN prediction\n",
    "\n",
    "    response = output.strip().lower()\n",
    "\n",
    "    # Clean multiline output\n",
    "    lines = [line.strip() for line in response.splitlines() if line.strip()]\n",
    "    if lines:\n",
    "        response = lines[-1]\n",
    "\n",
    "    # Remove punctuation\n",
    "    response = response.replace(\".\", \"\").replace(\":\", \"\").strip()\n",
    "\n",
    "    # Normalize prediction\n",
    "    if response == \"positive\":\n",
    "        pred = \"Positive\"\n",
    "    elif response == \"negative\":\n",
    "        pred = \"Negative\"\n",
    "    elif \"positive\" in response:\n",
    "        pred = \"Positive\"\n",
    "    elif \"negative\" in response:\n",
    "        pred = \"Negative\"\n",
    "    else:\n",
    "        pred = \"Unknown\"\n",
    "\n",
    "    print(f\"\\nüì• Prompt: {prompt}\\nüß† Raw Response: {output}\\n‚úÖ Cleaned Prediction: {pred}\")\n",
    "\n",
    "    \n",
    "    predictions.append({\n",
    "        \"text\": row[\"text\"],\n",
    "        \"true_label\": row[\"true_label\"],\n",
    "        \"prediction\": pred\n",
    "    })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ea8558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 20\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(predictions)\n",
    "print(\"Total predictions:\", len(result_df))\n",
    "result_df.head()\n",
    "result_df.to_csv(r\"D:\\Zoro_project2\\zero-short-text-classification\\results\\sst2_flan_predictions_sample.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b9574e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuracy: 0.9500\n",
      "F1 Score: 0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "filtered = result_df[result_df[\"prediction\"] != \"Unknown\"]\n",
    "acc = accuracy_score(filtered[\"true_label\"], filtered[\"prediction\"])\n",
    "f1 = f1_score(filtered[\"true_label\"], filtered[\"prediction\"], pos_label=\"Positive\")\n",
    "\n",
    "print(f\"\\n Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400be19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04070c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74bf21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py_3)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
